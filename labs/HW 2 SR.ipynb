{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1) Implement KNN classification, using the sklearn package. \n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2) Use the sklearn package to implement cross-validation for your \n",
    "# classifier. Use 5 folds for your cross-validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3) Use your KNN classifier and cross-validation code from (1) and (2) \n",
    "# above to determine the optimal value of K (number of nearest neighbors to consult) \n",
    "# for this Iris dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 4) Using matplotlib, plot classifier accuracy versus the hyperparameter K for a range \n",
    "# of K that you consider interesting. Explain in words what you are seeing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 5) Now, write your own implementation of cross-validation in Python without using \n",
    "# the cross-validation methods from sklearn. Cross validation is a very important concept. \n",
    "# Implementing it yourself in Python is the best way to learn and understand it. \n",
    "# Compare the results of your cross-validation code with your results using the \n",
    "# cross-validation in sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 6) EXTRA CREDIT 1: Using the value of K obtained in (3) above, vary the number of folds \n",
    "# used for cross-validation across an interesting range, e.g. [ 2, 3, 5, 6, 10, 15]. \n",
    "# How does classifier accuracy vary with the number of folds used? \n",
    "# Do you think there exists an optimal number of folds to use for this particular problem? \n",
    "# Why or why not?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 7) EXTRA CREDIT 2: Write your own implementation of KNN classification in Python, \n",
    "# without using the methods from sklearn. Compare your results with the results you \n",
    "# obtained using sklearn."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
